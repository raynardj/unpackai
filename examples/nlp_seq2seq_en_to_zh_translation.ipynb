{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHvQR0D2pvEOAFSDPzBnca",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "94111dfb9a2d4a4f93e00bdb34c70090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_659eee19636c45da881d243f66aedf27",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff2e02e62d0b438cac9f521da8c0d5eb",
              "IPY_MODEL_fc66ee3afa1944beb42494efbb1301ac",
              "IPY_MODEL_9ac2a1e65c084bca8cdff9f1dc7541e0"
            ]
          }
        },
        "659eee19636c45da881d243f66aedf27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff2e02e62d0b438cac9f521da8c0d5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_db73dbc0dabc429481860871b02dc9e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3486fd1f15b43068e47df0ad6a81559"
          }
        },
        "fc66ee3afa1944beb42494efbb1301ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c8dad1a95c8646edbde1af6fcc3f0ff9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb2e04bed86047b0b3a4e587cfb48ef0"
          }
        },
        "9ac2a1e65c084bca8cdff9f1dc7541e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_579055f403bf4594a2c665adfdfb8995",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00, 21.65it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94765776469249ea94eee8ccf64c47e7"
          }
        },
        "db73dbc0dabc429481860871b02dc9e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3486fd1f15b43068e47df0ad6a81559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8dad1a95c8646edbde1af6fcc3f0ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb2e04bed86047b0b3a4e587cfb48ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "579055f403bf4594a2c665adfdfb8995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94765776469249ea94eee8ccf64c47e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unpackAI/unpackai/blob/main/examples/nlp_seq2seq_en_to_zh_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EtssVJyGkmU"
      },
      "source": [
        "# Sequence to sequence model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7mp4E5IILWU"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbSOudesCVRX"
      },
      "source": [
        "!pip install -q unpackai==0.1.8.9\n",
        "!pip install -q transformers\n",
        "!pip install -Uqq fastai"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkYktRK2IAqq"
      },
      "source": [
        "!pip install -q datasets"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEayBpuJIOdM"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdOJ0FtMCZwa"
      },
      "source": [
        "from datasets import load_dataset\n",
        "from fastai.text.all import *\n",
        "from unpackai.nlp import *"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbXuwqr0KEr8"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "94111dfb9a2d4a4f93e00bdb34c70090",
            "659eee19636c45da881d243f66aedf27",
            "ff2e02e62d0b438cac9f521da8c0d5eb",
            "fc66ee3afa1944beb42494efbb1301ac",
            "9ac2a1e65c084bca8cdff9f1dc7541e0",
            "db73dbc0dabc429481860871b02dc9e0",
            "b3486fd1f15b43068e47df0ad6a81559",
            "c8dad1a95c8646edbde1af6fcc3f0ff9",
            "bb2e04bed86047b0b3a4e587cfb48ef0",
            "579055f403bf4594a2c665adfdfb8995",
            "94765776469249ea94eee8ccf64c47e7"
          ]
        },
        "id": "lKxBUAPgDNcF",
        "outputId": "adbbf022-09b1-4891-c8ff-6a08721a6234"
      },
      "source": [
        "# also en-ru, en-fr, en-it, etc\n",
        "dataset = load_dataset(\"ted_iwlst2013\", 'en-zh',) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset ted_iwlst2013 (/root/.cache/huggingface/datasets/ted_iwlst2013/en-zh/1.1.0/769086006155211ed7233545de12bce6fe41e1c71f509a3f062e294cb3c00e99)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94111dfb9a2d4a4f93e00bdb34c70090",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9uFZ5uzKdmH",
        "outputId": "5866bd6e-6800-44e9-e188-28d6c4f11324"
      },
      "source": [
        "dataset\n",
        "entire = dataset['train']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 154579\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pike-iY6LDFG"
      },
      "source": [
        "### Split data to train/valid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3CukZZvKaVq"
      },
      "source": [
        "The dataset we donwloaded doesn't contain validation, let's split to make one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuMbjgmKKMh6",
        "outputId": "7e516e38-8124-4896-c22e-781e89be300c"
      },
      "source": [
        "splited = entire.train_test_split(test_size = .1,)\n",
        "splited"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ted_iwlst2013/en-zh/1.1.0/769086006155211ed7233545de12bce6fe41e1c71f509a3f062e294cb3c00e99/cache-64b6ac3983d87e67.arrow and /root/.cache/huggingface/datasets/ted_iwlst2013/en-zh/1.1.0/769086006155211ed7233545de12bce6fe41e1c71f509a3f062e294cb3c00e99/cache-4167f5cdef840354.arrow\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 139121\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 15458\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlpBQ1eBI5Ey"
      },
      "source": [
        "train = splited['train']\n",
        "valid = splited['test']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H04lDYOLJdLQ",
        "outputId": "925312e5-51e6-479c-f130-6ecd474b25a6"
      },
      "source": [
        "train[30]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '86514',\n",
              " 'translation': {'en': 'And now my mission to control and predict had turned up the answer that the way to live is with vulnerability and to stop controlling and predicting.',\n",
              "  'zh': '而我现在的使命 即控制并预测 却给出了这样一个结果：要想与脆弱共存 就得停止控制，停止预测'}}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MmybrdGmT2w"
      },
      "source": [
        "## Tokenizer and pretrained model\n",
        "> Tokenizer will be a part the data pipeline, so let's download the pretrained tokenizer and pretrained model before we create a data block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukyVGg8HmSd-"
      },
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoModel,\n",
        "    EncoderDecoderModel\n",
        "    )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3irjPISPqESN"
      },
      "source": [
        "# we find a English parsing encoder, as a pretrained bert is good at understanding english\n",
        "# BERT is short for Bidirectional **Encoder** Representations from Transformers, which consists fully of encoder blocks\n",
        "ENCODER_PRETRAINED = \"bert-base-uncased\"\n",
        "# we find a Chinese writing model for decoder, as decoder is the part of the model that can write stuff\n",
        "DECODER_PRETRAINED = \"uer/gpt2-chinese-poem\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92iwRu6Oqbzb"
      },
      "source": [
        "### Load pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZkPxJVTm8Ng",
        "outputId": "dcecf16e-22fe-4c25-9ffb-aae9d75785f3"
      },
      "source": [
        "encoder = AutoModel.from_pretrained(ENCODER_PRETRAINED)\n",
        "decoder = AutoModelForCausalLM.from_pretrained(DECODER_PRETRAINED, add_cross_attention=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at uer/gpt2-chinese-poem and are newly initialized: ['transformer.h.2.ln_cross_attn.weight', 'transformer.h.6.ln_cross_attn.weight', 'transformer.h.11.crossattention.q_attn.weight', 'transformer.h.4.crossattention.c_attn.weight', 'transformer.h.11.ln_cross_attn.weight', 'transformer.h.5.crossattention.c_attn.weight', 'transformer.h.2.crossattention.masked_bias', 'transformer.h.9.crossattention.c_proj.bias', 'transformer.h.5.crossattention.q_attn.weight', 'transformer.h.3.crossattention.bias', 'transformer.h.6.crossattention.c_proj.weight', 'transformer.h.5.crossattention.c_proj.bias', 'transformer.h.0.crossattention.q_attn.weight', 'transformer.h.3.crossattention.c_proj.bias', 'transformer.h.8.crossattention.c_proj.weight', 'transformer.h.3.crossattention.q_attn.weight', 'transformer.h.5.crossattention.c_proj.weight', 'transformer.h.7.ln_cross_attn.weight', 'transformer.h.1.crossattention.c_attn.weight', 'transformer.h.6.crossattention.masked_bias', 'transformer.h.9.crossattention.c_attn.weight', 'transformer.h.2.crossattention.c_proj.bias', 'transformer.h.11.crossattention.c_proj.weight', 'transformer.h.2.crossattention.bias', 'transformer.h.10.crossattention.c_proj.weight', 'transformer.h.8.crossattention.c_proj.bias', 'transformer.h.4.crossattention.q_attn.weight', 'transformer.h.6.crossattention.bias', 'transformer.h.9.ln_cross_attn.weight', 'transformer.h.0.crossattention.bias', 'transformer.h.8.crossattention.q_attn.weight', 'transformer.h.11.crossattention.c_attn.weight', 'transformer.h.9.crossattention.c_proj.weight', 'transformer.h.11.crossattention.masked_bias', 'transformer.h.1.crossattention.q_attn.weight', 'transformer.h.3.crossattention.c_proj.weight', 'transformer.h.0.crossattention.c_attn.weight', 'transformer.h.10.crossattention.q_attn.weight', 'transformer.h.6.crossattention.q_attn.weight', 'transformer.h.11.crossattention.bias', 'transformer.h.2.crossattention.c_attn.weight', 'transformer.h.11.crossattention.c_proj.bias', 'transformer.h.3.crossattention.masked_bias', 'transformer.h.9.crossattention.masked_bias', 'transformer.h.7.crossattention.c_attn.weight', 'transformer.h.8.crossattention.masked_bias', 'transformer.h.4.ln_cross_attn.weight', 'transformer.h.3.crossattention.c_attn.weight', 'transformer.h.10.crossattention.bias', 'transformer.h.1.crossattention.bias', 'transformer.h.6.crossattention.c_attn.weight', 'transformer.h.4.crossattention.c_proj.bias', 'transformer.h.9.crossattention.q_attn.weight', 'transformer.h.7.crossattention.q_attn.weight', 'transformer.h.0.ln_cross_attn.weight', 'transformer.h.0.crossattention.c_proj.weight', 'transformer.h.8.crossattention.c_attn.weight', 'transformer.h.5.crossattention.bias', 'transformer.h.5.crossattention.masked_bias', 'transformer.h.2.crossattention.q_attn.weight', 'transformer.h.2.crossattention.c_proj.weight', 'transformer.h.10.crossattention.c_attn.weight', 'transformer.h.7.crossattention.c_proj.weight', 'transformer.h.0.crossattention.c_proj.bias', 'transformer.h.7.crossattention.masked_bias', 'transformer.h.1.crossattention.c_proj.weight', 'transformer.h.6.crossattention.c_proj.bias', 'transformer.h.0.crossattention.masked_bias', 'transformer.h.8.crossattention.bias', 'transformer.h.7.crossattention.bias', 'transformer.h.8.ln_cross_attn.weight', 'transformer.h.1.crossattention.masked_bias', 'transformer.h.7.crossattention.c_proj.bias', 'transformer.h.5.ln_cross_attn.weight', 'transformer.h.10.crossattention.masked_bias', 'transformer.h.10.crossattention.c_proj.bias', 'transformer.h.10.ln_cross_attn.weight', 'transformer.h.1.ln_cross_attn.weight', 'transformer.h.1.crossattention.c_proj.bias', 'transformer.h.4.crossattention.bias', 'transformer.h.4.crossattention.masked_bias', 'transformer.h.4.crossattention.c_proj.weight', 'transformer.h.9.crossattention.bias', 'transformer.h.3.ln_cross_attn.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlmjIjq-qdnx"
      },
      "source": [
        "### Load pretrained tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkP89dOrp5LQ"
      },
      "source": [
        "encoder_tokenizer = AutoTokenizer.from_pretrained(ENCODER_PRETRAINED)\n",
        "decoder_tokenizer = AutoTokenizer.from_pretrained(DECODER_PRETRAINED)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF2n51lcrERy",
        "outputId": "a250d043-1942-4b61-d102-f027b63b88bb"
      },
      "source": [
        "ENCODER_MAX_LEN = encoder.config.max_position_embeddings\n",
        "DECODER_MAX_LEN = decoder.config.max_position_embeddings\n",
        "\n",
        "ENCODER_MAX_LEN, DECODER_MAX_LEN"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYxYmZxJsAn1"
      },
      "source": [
        "tokenizer_configuration = dict(\n",
        "    return_tensors='pt',\n",
        "    max_length=128,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WGAifAmLWZq"
      },
      "source": [
        "### Datablock"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpUcPI0_-fkJ"
      },
      "source": [
        "You can try to change get_x and get_y to fetch the opposite language, you can have model that will train in other direction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2J5hRqpLiU8"
      },
      "source": [
        "dblock = DataBlock(\n",
        "    get_x = lambda x:x['translation']['en'],\n",
        "    get_y = lambda x:x['translation']['zh'],\n",
        "                   )"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDrINV_8MZSR"
      },
      "source": [
        "### Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coJ9e8g2L8h5",
        "outputId": "cb412ed0-f9b6-41dc-c1cd-eed9a25c6d79"
      },
      "source": [
        "dsets = dblock.datasets(train, valid)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting items from Dataset({\n",
            "    features: ['id', 'translation'],\n",
            "    num_rows: 139121\n",
            "})\n",
            "Found 139121 items\n",
            "2 datasets of sizes 111297,27824\n",
            "Setting up Pipeline: <lambda>\n",
            "Setting up Pipeline: <lambda>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuyufMt_-sjB"
      },
      "source": [
        "Preview a row of dataset, which returns an English sentence vs Chinese sentence pair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqgmmbGOMRF3",
        "outputId": "9b987eae-59e6-4ed2-ee95-dd1549e51e8a"
      },
      "source": [
        "dsets.train[6]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Now you prepare for the inevitable.', '现在 你要为不可避免的事情做准备')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3uF1ieMLYjr"
      },
      "source": [
        "### Dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f87qAv51-201"
      },
      "source": [
        "* Dataset deals data on **row** level, eg. a pair of sentence\n",
        "* Dataloader deals data on **batch** level, eg. a batch of tensor, consists of $n$ rows of data, where $n$ is the batch size\n",
        "\n",
        "We usually call this process of: rows of raw data => pytorch tensor: collate\n",
        "\n",
        "Here we build a collate function that will transform rows of 2 sentences into tokenized/numericalize tensors using given tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdcqUHfVqkXS"
      },
      "source": [
        "def batch_tokenize_collate(data):\n",
        "    input_seq, target_seq = list(zip(*data))\n",
        "    # tokenizing for encoder\n",
        "    x = encoder_tokenizer(list(input_seq),**tokenizer_configuration)\n",
        "    input_ids = x.input_ids\n",
        "    attention_mask = x.attention_mask\n",
        "\n",
        "    # tokenizing for decoder\n",
        "    y = decoder_tokenizer(list(target_seq),**tokenizer_configuration)\n",
        "    decoder_input_ids = y.input_ids\n",
        "    decoder_attention_mask = y.attention_mask\n",
        "    \n",
        "    # return the output in format of (x, y), y\n",
        "    # As the model forward pipeline will need both x, and y for training\n",
        "    # and will output loss directly, but fastai learner require x,y formality in datablock\n",
        "    return (input_ids, attention_mask, decoder_input_ids, decoder_attention_mask),\\\n",
        "        ( decoder_input_ids, decoder_attention_mask)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf2kE7VZlGrQ"
      },
      "source": [
        "dls = dsets.dataloaders(bs=8,\n",
        "                        create_batch=batch_tokenize_collate)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrwCllAstD8p",
        "outputId": "ea6978e5-04c3-471d-82fa-326e421e5340"
      },
      "source": [
        "dls.one_batch()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((tensor([[ 101, 2057, 2202,  ...,    0,    0,    0],\n",
              "          [ 101, 2074, 2061,  ...,    0,    0,    0],\n",
              "          [ 101, 4067, 2017,  ...,    0,    0,    0],\n",
              "          ...,\n",
              "          [ 101, 2061, 2057,  ...,    0,    0,    0],\n",
              "          [ 101, 4312, 1010,  ...,    0,    0,    0],\n",
              "          [ 101, 5674, 2065,  ...,    0,    0,    0]], device='cuda:0'),\n",
              "  tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'),\n",
              "  tensor([[ 101, 2769,  812,  ...,    0,    0,    0],\n",
              "          [ 101, 2769, 2682,  ...,    0,    0,    0],\n",
              "          [ 101, 6468, 6468,  ...,    0,    0,    0],\n",
              "          ...,\n",
              "          [ 101, 8020,  830,  ...,    0,    0,    0],\n",
              "          [ 101, 8020, 5010,  ...,    0,    0,    0],\n",
              "          [ 101, 2682, 6496,  ...,    0,    0,    0]], device='cuda:0'),\n",
              "  tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')),\n",
              " (tensor([[ 101, 2769,  812,  ...,    0,    0,    0],\n",
              "          [ 101, 2769, 2682,  ...,    0,    0,    0],\n",
              "          [ 101, 6468, 6468,  ...,    0,    0,    0],\n",
              "          ...,\n",
              "          [ 101, 8020,  830,  ...,    0,    0,    0],\n",
              "          [ 101, 8020, 5010,  ...,    0,    0,    0],\n",
              "          [ 101, 2682, 6496,  ...,    0,    0,    0]], device='cuda:0'),\n",
              "  tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pajv5ridLamp"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1zqJXDsCUw-"
      },
      "source": [
        "We create a seq2seq model by using pretrained encoder + pretrained decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBVyNeKUv6FU"
      },
      "source": [
        "encoder_decoder = EncoderDecoderModel(encoder=encoder, decoder=decoder)\n",
        "\n",
        "class Seq2SeqTrain(nn.Module):\n",
        "    def __init__(self, encoder_decoder):\n",
        "        super().__init__()\n",
        "        self.encoder_decoder = encoder_decoder\n",
        "        \n",
        "    def forward(self, batch):\n",
        "        input_ids, attention_mask, decoder_input_ids, decoder_attention_mask = batch\n",
        "        return self.encoder_decoder(\n",
        "            input_ids = input_ids,\n",
        "            attention_mask = attention_mask,\n",
        "            decoder_input_ids = decoder_input_ids,\n",
        "            decoder_attention_mask = decoder_attention_mask,\n",
        "            labels = decoder_input_ids,\n",
        "        )"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uIjcPuXw0Fr"
      },
      "source": [
        "model = Seq2SeqTrain(encoder_decoder)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBf3NTKSLcUb"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhFB_o7GK6-Y"
      },
      "source": [
        "learn = Learner(dls,model,loss_func=lambda output, target:output.loss,)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "id": "4wcfC9k9xCV8",
        "outputId": "cbef631e-ac51-4381-fcae-785476fc4fad"
      },
      "source": [
        "learn.fit(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='331' class='' max='13912' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      2.38% [331/13912 05:43<3:54:53 1.2652]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SFWnZ38_To0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}