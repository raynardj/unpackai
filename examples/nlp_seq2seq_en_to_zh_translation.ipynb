{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "94111dfb9a2d4a4f93e00bdb34c70090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff2e02e62d0b438cac9f521da8c0d5eb",
              "IPY_MODEL_fc66ee3afa1944beb42494efbb1301ac",
              "IPY_MODEL_9ac2a1e65c084bca8cdff9f1dc7541e0"
            ],
            "layout": "IPY_MODEL_659eee19636c45da881d243f66aedf27"
          }
        },
        "659eee19636c45da881d243f66aedf27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff2e02e62d0b438cac9f521da8c0d5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3486fd1f15b43068e47df0ad6a81559",
            "placeholder": "​",
            "style": "IPY_MODEL_db73dbc0dabc429481860871b02dc9e0",
            "value": "100%"
          }
        },
        "fc66ee3afa1944beb42494efbb1301ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb2e04bed86047b0b3a4e587cfb48ef0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8dad1a95c8646edbde1af6fcc3f0ff9",
            "value": 1
          }
        },
        "9ac2a1e65c084bca8cdff9f1dc7541e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94765776469249ea94eee8ccf64c47e7",
            "placeholder": "​",
            "style": "IPY_MODEL_579055f403bf4594a2c665adfdfb8995",
            "value": " 1/1 [00:00&lt;00:00, 21.65it/s]"
          }
        },
        "db73dbc0dabc429481860871b02dc9e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3486fd1f15b43068e47df0ad6a81559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8dad1a95c8646edbde1af6fcc3f0ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb2e04bed86047b0b3a4e587cfb48ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "579055f403bf4594a2c665adfdfb8995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94765776469249ea94eee8ccf64c47e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unpackAI/unpackai/blob/main/examples/nlp_seq2seq_en_to_zh_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EtssVJyGkmU"
      },
      "source": [
        "# Sequence to sequence model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7mp4E5IILWU"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbSOudesCVRX"
      },
      "source": [
        "# !pip install -q unpackai==0.1.8.9\n",
        "# !pip install -q transformers\n",
        "# !pip install -Uqq fastai\n",
        "# !pip install -q datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEayBpuJIOdM"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdOJ0FtMCZwa"
      },
      "source": [
        "from datasets import load_dataset\n",
        "from fastai.text.all import *\n",
        "from unpackai.nlp import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbXuwqr0KEr8"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "94111dfb9a2d4a4f93e00bdb34c70090",
            "659eee19636c45da881d243f66aedf27",
            "ff2e02e62d0b438cac9f521da8c0d5eb",
            "fc66ee3afa1944beb42494efbb1301ac",
            "9ac2a1e65c084bca8cdff9f1dc7541e0",
            "db73dbc0dabc429481860871b02dc9e0",
            "b3486fd1f15b43068e47df0ad6a81559",
            "c8dad1a95c8646edbde1af6fcc3f0ff9",
            "bb2e04bed86047b0b3a4e587cfb48ef0",
            "579055f403bf4594a2c665adfdfb8995",
            "94765776469249ea94eee8ccf64c47e7",
            "5806c0c651d34bac9f3a8d5cb573743d"
          ]
        },
        "id": "lKxBUAPgDNcF",
        "outputId": "adbbf022-09b1-4891-c8ff-6a08721a6234"
      },
      "source": [
        "# also en-ru, en-fr, en-it, etc\n",
        "dataset = load_dataset(\"ted_iwlst2013\", 'en-zh') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing dataset ted_iwlst2013 (/root/.cache/huggingface/datasets/ted_iwlst2013/en-zh/1.1.0/769086006155211ed7233545de12bce6fe41e1c71f509a3f062e294cb3c00e99)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5806c0c651d34bac9f3a8d5cb573743d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9uFZ5uzKdmH"
      },
      "source": [
        "dataset\n",
        "entire = dataset['train']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pike-iY6LDFG"
      },
      "source": [
        "### Split data to train/valid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3CukZZvKaVq"
      },
      "source": [
        "The dataset we donwloaded doesn't contain validation, let's split to make one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuMbjgmKKMh6",
        "outputId": "7e516e38-8124-4896-c22e-781e89be300c"
      },
      "source": [
        "splited = entire.train_test_split(test_size = .1,)\n",
        "splited"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ted_iwlst2013/en-zh/1.1.0/769086006155211ed7233545de12bce6fe41e1c71f509a3f062e294cb3c00e99/cache-64b6ac3983d87e67.arrow and /root/.cache/huggingface/datasets/ted_iwlst2013/en-zh/1.1.0/769086006155211ed7233545de12bce6fe41e1c71f509a3f062e294cb3c00e99/cache-4167f5cdef840354.arrow\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 139121\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 15458\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlpBQ1eBI5Ey"
      },
      "source": [
        "train = splited['train']\n",
        "valid = splited['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H04lDYOLJdLQ",
        "outputId": "925312e5-51e6-479c-f130-6ecd474b25a6"
      },
      "source": [
        "train[30]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'translation': {'en': 'And now my mission to control and predict had turned up the answer that the way to live is with vulnerability and to stop controlling and predicting.',\n",
              "  'zh': '而我现在的使命 即控制并预测 却给出了这样一个结果：要想与脆弱共存 就得停止控制，停止预测'},\n",
              " 'id': '86514'}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MmybrdGmT2w"
      },
      "source": [
        "## Tokenizer and pretrained model\n",
        "> Tokenizer will be a part the data pipeline, so let's download the pretrained tokenizer and pretrained model before we create a data block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukyVGg8HmSd-"
      },
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoModel,\n",
        "    EncoderDecoderModel\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3irjPISPqESN"
      },
      "source": [
        "# we find a English parsing encoder, as a pretrained bert is good at understanding english\n",
        "# BERT is short for Bidirectional **Encoder** Representations from Transformers, which consists fully of encoder blocks\n",
        "ENCODER_PRETRAINED = \"bert-base-uncased\"\n",
        "# we find a Chinese writing model for decoder, as decoder is the part of the model that can write stuff\n",
        "DECODER_PRETRAINED = \"uer/gpt2-chinese-poem\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92iwRu6Oqbzb"
      },
      "source": [
        "### Load pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZkPxJVTm8Ng"
      },
      "source": [
        "# encoder = AutoModel.from_pretrained(ENCODER_PRETRAINED, proxies={\"http\":\"bifrost:3128\"})\n",
        "# decoder = AutoModelForCausalLM.from_pretrained(DECODER_PRETRAINED, add_cross_attention=True,\n",
        "#                                                proxies={\"http\":\"bifrost:3128\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlmjIjq-qdnx"
      },
      "source": [
        "### Load pretrained tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkP89dOrp5LQ"
      },
      "source": [
        "encoder_tokenizer = AutoTokenizer.from_pretrained(ENCODER_PRETRAINED)\n",
        "decoder_tokenizer = AutoTokenizer.from_pretrained(DECODER_PRETRAINED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF2n51lcrERy"
      },
      "source": [
        "# ENCODER_MAX_LEN = encoder.config.max_position_embeddings\n",
        "# DECODER_MAX_LEN = decoder.config.max_position_embeddings\n",
        "\n",
        "# ENCODER_MAX_LEN, DECODER_MAX_LEN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYxYmZxJsAn1"
      },
      "source": [
        "tokenizer_configuration = dict(\n",
        "    return_tensors='pt',\n",
        "    max_length=128,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WGAifAmLWZq"
      },
      "source": [
        "### Datablock"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpUcPI0_-fkJ"
      },
      "source": [
        "You can try to change get_x and get_y to fetch the opposite language, you can have model that will train in other direction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2J5hRqpLiU8"
      },
      "source": [
        "dblock = DataBlock(\n",
        "    get_x = lambda x:x['translation']['en'],\n",
        "    get_y = lambda x:x['translation']['zh'],\n",
        "                   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDrINV_8MZSR"
      },
      "source": [
        "### Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coJ9e8g2L8h5",
        "outputId": "cb412ed0-f9b6-41dc-c1cd-eed9a25c6d79"
      },
      "source": [
        "dsets = dblock.datasets(train, valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting items from Dataset({\n",
            "    features: ['id', 'translation'],\n",
            "    num_rows: 139121\n",
            "})\n",
            "Found 139121 items\n",
            "2 datasets of sizes 111297,27824\n",
            "Setting up Pipeline: <lambda>\n",
            "Setting up Pipeline: <lambda>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuyufMt_-sjB"
      },
      "source": [
        "Preview a row of dataset, which returns an English sentence vs Chinese sentence pair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqgmmbGOMRF3",
        "outputId": "9b987eae-59e6-4ed2-ee95-dd1549e51e8a"
      },
      "source": [
        "dsets.train[6]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('But the information was closer to me.', '但这些知识却离我更近了。')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3uF1ieMLYjr"
      },
      "source": [
        "### Dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f87qAv51-201"
      },
      "source": [
        "* Dataset deals data on **row** level, eg. a pair of sentence\n",
        "* Dataloader deals data on **batch** level, eg. a batch of tensor, consists of $n$ rows of data, where $n$ is the batch size\n",
        "\n",
        "We usually call this process of: rows of raw data => pytorch tensor: collate\n",
        "\n",
        "Here we build a collate function that will transform rows of 2 sentences into tokenized/numericalize tensors using given tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdcqUHfVqkXS"
      },
      "source": [
        "def batch_tokenize_collate(data):\n",
        "    input_seq, target_seq = list(zip(*data))\n",
        "    # tokenizing for encoder\n",
        "    x = encoder_tokenizer(list(input_seq),**tokenizer_configuration)\n",
        "    input_ids = x.input_ids\n",
        "    attention_mask = x.attention_mask\n",
        "\n",
        "    # tokenizing for decoder\n",
        "    y = decoder_tokenizer(list(target_seq),**tokenizer_configuration)\n",
        "    decoder_input_ids = y.input_ids\n",
        "    decoder_attention_mask = y.attention_mask\n",
        "    \n",
        "    # return the output in format of (x, y), y\n",
        "    # As the model forward pipeline will need both x, and y for training\n",
        "    # and will output loss directly, but fastai learner require x,y formality in datablock\n",
        "    return (input_ids, attention_mask, decoder_input_ids, decoder_attention_mask),\\\n",
        "        ( decoder_input_ids, decoder_attention_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf2kE7VZlGrQ"
      },
      "source": [
        "dls = dsets.dataloaders(bs=64,\n",
        "                        create_batch=batch_tokenize_collate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0EbwhK3fM69"
      },
      "source": [
        "(input_ids, attention_mask, decoder_input_ids, decoder_attention_mask),(\n",
        "    decoder_input_ids, decoder_attention_mask)=dls.one_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpcOOSdmfM69"
      },
      "source": [
        "### Reconstruct a batch of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ji6bVBBfM69",
        "outputId": "83f4c920-4fa7-4878-9268-0e749ae1b956"
      },
      "source": [
        "for e,c in zip(encoder_tokenizer.batch_decode(input_ids, skip_special_tokens=True),\n",
        "decoder_tokenizer.batch_decode(decoder_input_ids, skip_special_tokens=True)):\n",
        "    print(e)\n",
        "    print(c)\n",
        "    print(\"=\"*10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "well, there are lots of reasons.\n",
            "这 有 很 多 原 因\n",
            "==========\n",
            "even if you're logged out, one engineer told me, there are 57 signals that google looks at - - everything from what kind of computer you're on to what kind of browser you're using to where you're located - - that it uses to personally tailor your query results.\n",
            "一 位 工 程 师 告 诉 我 ， 即 使 你 退 出 帐 号 ， 还 会 有 57 种 信 号 可 供 谷 歌 参 考 - - 几 乎 所 有 的 信 息 ： 从 你 使 用 的 电 脑 型 号 到 你 用 的 浏 览 器 到 你 所 在 的 位 置 - - 谷 歌 利 用 这 些 为 你 定 制 出 个 性 化 的 查 询 结 果 。\n",
            "==========\n",
            "but it has to be done together.\n",
            "这 必 须 由 你 们 共 同 参 与 完 成 。\n",
            "==========\n",
            "the whole business is run on sustainable energy.\n",
            "整 间 餐 厅 都 是 使 用 可 再 生 能 源 ，\n",
            "==========\n",
            "he said, \" you know what, one of the items on the checklist is lack of remorse, but another item on the checklist is cunning, manipulative.\n",
            "他 说 ， 你 知 道 吗 ， 检 核 表 上 有 一 项 是 缺 乏 懊 悔 但 另 一 项 却 是 狡 猾 ， 且 控 制 欲 强\n",
            "==========\n",
            "and one of the most common faces on something faced with beauty, something stupefyingly delicious, is what i call the omg.\n",
            "面 对 美 的 最 常 见 的 表 情 之 一 那 种 面 对 难 以 置 信 的 美 味 时 的 表 情 就 是 我 的 神 啊\n",
            "==========\n",
            "only the best ones can survive.\n",
            "只 有 最 好 那 些 的 才 能 保 留 下 来 。\n",
            "==========\n",
            "this is a collaboration between myself and don.\n",
            "这 是 我 和 don 的 合 作 。\n",
            "==========\n",
            "and we wondered how they use these bizarre toes to climb up a wall so quickly.\n",
            "我 们 很 想 知 道 壁 虎 是 如 何 用 这 些 奇 怪 的 脚 趾 来 飞 快 地 爬 墙 。\n",
            "==========\n",
            "could it be - - a devastating question, a question that was framed for me by nicholas negroponte - - could it be that we are heading towards or maybe in a future where knowing is obsolete?\n",
            "会 不 会 变 成 尼 葛 洛 庞 帝 （ nicholas negroponte ） 提 了 一 个 非 常 棘 手 的 问 题 ， 难 住 了 我 会 不 会 变 成 我 们 所 向 往 的 那 样 又 或 者 在 将 来 连 知 识 都 会 过 时 了 ？\n",
            "==========\n",
            "and that is my vision for your future.\n",
            "那 就 是 我 对 你 们 未 来 的 想 象 。\n",
            "==========\n",
            "i wonder if that's true.\n",
            "我 怀 疑 其 真 实 性 。\n",
            "==========\n",
            "could you say that again? what's your favorite singing group?\n",
            "你 能 再 说 一 遍 吗 ？ 你 最 喜 欢 的 演 唱 组 合 是 ？\n",
            "==========\n",
            "i have been really lucky with this technology : all of a sudden as it is ready, the world is ready to accept it.\n",
            "这 项 技 术 确 实 给 我 带 来 了 好 运 当 这 项 技 术 成 熟 了 ， 这 个 世 界 也 就 准 备 好 了 接 受\n",
            "==========\n",
            "they own their success. but they also own their failure.\n",
            "人 们 拥 有 成 功 ， 也 拥 有 失 败\n",
            "==========\n",
            "so i hope you can see.\n",
            "我 希 望 你 们 能 看 到 。\n",
            "==========\n",
            "and about a year ago, an internet dating service, match. com, came to me and asked me if i would design a new dating site for them.\n",
            "大 约 一 年 前 ， 一 个 网 络 婚 介 服 务 公 司 match. com 找 到 我 想 让 我 为 他 们 设 计 一 个 新 的 约 会 站 点\n",
            "==========\n",
            "and then my pickled jellyfish at the hong kong supermarket on route 18 in east brunswick.\n",
            "腌 海 蜇 皮 这 是 在 东 布 伦 瑞 克 的 18 号 路 上 的 香 港 超 市\n",
            "==========\n",
            "and i said, \" oh my god, this is going to suck. \"\n",
            "我 说 ： 哦 ， 我 的 天 ， 要 悲 剧 了 。\n",
            "==========\n",
            "we ought to take them out back and shoot them, and put bounty hunters after them.\n",
            "我 们 应 该 把 它 们 拖 出 去 枪 毙 ， 还 要 让 它 们 永 不 翻 身\n",
            "==========\n",
            "this message is given as a public service.\n",
            "这 个 信 息 作 为 一 项 公 共 福 利 而 告 知 大 家 。\n",
            "==========\n",
            "one is bundled up into one sausage.\n",
            "一 条 卷 起 来 进 到 一 条 香 肠 里\n",
            "==========\n",
            "that's the news from downtown. here it is in perspective.\n",
            "这 是 来 自 城 市 的 声 音 。 这 是 从 太 空 看 到 的 图 景\n",
            "==========\n",
            "and so now all the birds come in. and i have hawks.\n",
            "现 在 所 有 的 鸟 类 来 的 ， 我 还 有 了 老 鹰 。\n",
            "==========\n",
            "so he started selling marijuana.\n",
            "所 以 他 开 始 卖 大 麻 。\n",
            "==========\n",
            "i have one climate crisis ; i don't really need the second one. \"\n",
            "我 已 经 有 一 个 气 候 危 机 ； 我 确 实 不 需 要 第 二 个 。\n",
            "==========\n",
            "and as you'll see in this simulation, as they interact they gain points, as it were, they grow, and when they've doubled in size, you'll see them split, and that's how they reproduce and the population grows.\n",
            "你 们 可 以 在 模 拟 中 看 到 在 互 相 交 流 中 它 们 都 达 到 目 的 ， 迅 速 成 长 当 它 们 长 大 2 倍 大 的 时 候 ， 你 看 见 它 们 分 裂 这 就 是 它 们 如 何 繁 殖 ， 数 量 是 如 何 增 加 的\n",
            "==========\n",
            "sayyid qutb is one of the founding fathers of fanatical islam, one of the ideologues that inspired osama bin laden.\n",
            "萨 伊 德 · 库 （ sayyid qutb ） 是 狂 热 伊 斯 兰 教 的 创 始 人 之 一 也 是 奥 萨 马 · 本 拉 登 的 灵 感 源 泉 之 一\n",
            "==========\n",
            "pm : but now we're trying to get the video. there we go.\n",
            "但 现 在 我 们 试 一 下 影 像 。 好 了 。\n",
            "==========\n",
            "within the sphere of people who have that view, and it's a large number of people in the muslim world who disagree with bin laden in his application, but agree that islam is the answer.\n",
            "持 有 这 种 观 点 的 人 ， 在 穆 斯 林 世 界 中 非 常 多 他 们 虽 然 不 同 意 本 拉 登 的 做 法 ， 却 同 意 伊 斯 兰 教 是 解 决 问 题 的 答 案 。\n",
            "==========\n",
            "and here's the rub.\n",
            "而 这 是 最 难 的 地 方 。\n",
            "==========\n",
            "and the gun went off, and all i remember was finishing last and fighting back tears of frustration and incredible - - incredible - - this feeling of just being overwhelmed.\n",
            "当 发 令 枪 一 响 ， 我 唯 一 能 回 忆 起 来 的 就 是 最 后 一 个 才 跑 完 ， 你 能 了 解 么 ， 努 力 地 把 失 望 的 泪 水 往 肚 子 里 咽 ， 还 有 这 难 以 置 信 ， 难 以 置 信 的 被 彻 底 打 倒 的 感 觉 。\n",
            "==========\n",
            "second one : can you light a little torch - bulb with a battery bulb and one piece of wire?\n",
            "你 能 用 一 枚 电 池 和 一 根 电 线 点 亮 灯 泡 吗 ？\n",
            "==========\n",
            "and it was extraordinary to be taken by a priest.\n",
            "被 神 父 带 领 是 个 很 神 奇 的 经 历\n",
            "==========\n",
            "a group of men march through the streets cutting themselves with knives.\n",
            "一 群 人 游 行 ， 用 刀 割 自 己 。\n",
            "==========\n",
            "we went out and we found some visionary people with enough money to let us design and build these things, and in hopefully enough time to get them accepted.\n",
            "我 们 遇 过 一 些 有 远 见 的 人 提 供 足 够 资 金 ， 让 我 们 研 发 这 东 西 希 望 给 了 我 们 足 够 的 时 间 让 他 们 满 意 。\n",
            "==========\n",
            "but, you know, it has a benefit in terms of future longevity.\n",
            "就 未 来 长 寿 而 言 ， 它 确 实 有 好 处 。\n",
            "==========\n",
            "some people - - i've got an english friend in china, and he said, \" the continent is sleepwalking into oblivion. \"\n",
            "有 人 ， 我 有 一 个 在 中 国 的 英 国 朋 友 ， 他 说 ， 旧 大 陆 在 梦 游 似 的 会 被 遗 忘 。\n",
            "==========\n",
            "there's a little ledge inside, so the tea is sitting there and the water is filling it up like that.\n",
            "里 面 有 一 条 横 挡 茶 就 在 这 个 地 方 水 慢 慢 的 浸 透 茶 身\n",
            "==========\n",
            "and we forgot that people made choices and decisions.\n",
            "我 们 忘 了 人 们 是 会 做 选 择 、 做 决 定 的\n",
            "==========\n",
            "what might explain the difference in the experience of these two nearly identical men?\n",
            "是 什 么 原 因 让 这 两 个 几 乎 一 样 的 人 有 着 不 同 的 遭 遇 ？\n",
            "==========\n",
            "and also, what the antibodies use is a handle to essentially grab and neutralize the virus.\n",
            "同 样 也 是 抗 体 用 来 抓 住 并 且 压 制 这 些 病 毒 。\n",
            "==========\n",
            "i took a side trip to the american museum, and i never recovered.\n",
            "我 顺 便 去 了 美 国 博 物 馆 ， 从 来 没 有 回 过 神 来 。\n",
            "==========\n",
            "and then, from there, he climbed directly up the bark until he got to the top of the tree.\n",
            "接 着 ， 从 那 里 他 直 接 从 树 皮 爬 了 上 去 直 到 他 到 了 树 顶 。\n",
            "==========\n",
            "so here's a dinosaur that has spikes sticking out of its head, no dome and gnarly stuff on its nose.\n",
            "非 常 相 似 它 脑 后 也 有 钉 状 的 尖 刺 ， 鼻 子 上 有 瘤 状 物 但 没 有 颅 顶\n",
            "==========\n",
            "but if we detect those earliest moments, it'll bring us that much closer to an understanding of the big bang, which brings us that much closer to asking some of the hardest, most elusive, questions.\n",
            "但 是 ， 如 果 我 们 能 够 探 测 到 那 些 最 早 的 瞬 间 ， 它 还 将 使 我 们 离 理 解 大 爆 炸 更 进 一 步 ， 使 我 们 能 够 去 追 问 一 些 最 为 困 难 ， 同 时 也 最 为 飘 渺 的 问 题 。\n",
            "==========\n",
            "now, these ideas should apply across the board, as long as you can figure out why some organisms evolved to virulence.\n",
            "现 在 这 些 观 点 应 该 被 全 面 的 应 用 。 只 要 你 能 弄 明 白 为 什 么 一 些 病 菌 进 化 的 更 具 毒 性 。\n",
            "==========\n",
            "and if the tv was on, we were watching a documentary.\n",
            "如 果 电 视 开 着 ， 就 是 我 们 在 看 纪 录 片 。\n",
            "==========\n",
            "sun? no. well is there another name for a sunrise?\n",
            "sun 太 阳? 不 对 ， 有 近 义 词 吗 ？\n",
            "==========\n",
            "but we have given to the developing countries the technologies and the ways of thinking that are creating the crisis. this is in bolivia - - over thirty years.\n",
            "但 是 我 们 已 经 给 予 了 发 展 中 国 家 技 术 和 思 维 方 式 ， 这 些 东 西 导 致 了 气 候 危 机 。 这 里 是 玻 利 维 亚 ， 时 间 幅 度 为 三 十 年 。\n",
            "==========\n",
            "culture, design, humor, product design, technology\n",
            "culture, design, humor, product design, technology\n",
            "==========\n",
            "okay, well you have successfully completed your four quests, so let's see if i've successfully completed my mission to give you seven and a half minutes of bonus life.\n",
            "（ 笑 声 ） 好 的 ， 你 们 已 经 成 功 地 完 成 你 们 的 四 个 使 命 ， 所 以 现 在 看 看 我 是 否 也 成 功 完 成 我 的 使 命 延 长 你 们 了 七 分 半 钟 的 寿 命\n",
            "==========\n",
            "http : / / www. ted. com / talks / laurie _ garrett _ on _ lessons _ from _ the _ 1918 _ flu. html\n",
            "http : / / www. ted. com / talks / lang / zh - cn / laurie _ garrett _ on _ lessons _ from _ the _ 1918 _ flu. html\n",
            "==========\n",
            "755\n",
            "755\n",
            "==========\n",
            "this sets up consumer - driven healthcare.\n",
            "它 引 起 了 以 消 费 者 为 导 向 的 医 疗 革 命\n",
            "==========\n",
            "now, the best breeding ground for good comic writing is the stand - up comedy circuit, where they just happen to say that you kill when you do well and you bomb when you do badly.\n",
            "现 在 ， 优 秀 喜 剧 写 作 的 最 好 创 作 是 脱 口 秀 喜 剧 巡 演 ， 在 巡 演 中 的 行 话 ， 要 是 你 喜 剧 好 ， 你 会 征 服 所 有 人 ， 当 你 喜 剧 不 搞 笑 ， 你 就 倒 大 霉 了 。\n",
            "==========\n",
            "thank you very much.\n",
            "非 常 感 谢 大 家 。\n",
            "==========\n",
            "every south pole expedition you may have heard about is either flown out from the pole or has used vehicles or dogs or kites to do some kind of crossing - - no one has ever made a return journey. so that's the plan.\n",
            "每 一 支 你 们 听 说 过 的 南 极 探 险 队 从 极 点 返 回 时 ， 不 是 使 用 飞 机 就 是 汽 车 ， 狗 拉 雪 橇 ， 或 者 风 筝 来 实 现 穿 越 - - 没 人 尝 试 过 徒 步 返 回 。 所 以 ， 这 就 是 我 的 计 划 。\n",
            "==========\n",
            "and i wrote a lot of happy songs on my first record, which i still stand by, but this has got something else in it.\n",
            "我 为 我 的 第 一 张 唱 片 写 了 许 多 欢 欣 的 歌 曲 ， 现 在 我 依 然 坚 持 着 ， 但 这 首 歌 却 有 些 额 外 的 东 西 在 其 中 。\n",
            "==========\n",
            "and you know, the extraordinary part of it is i just simply had no answers.\n",
            "最 特 别 的 地 方 是 ， 我 没 有 答 案 ；\n",
            "==========\n",
            "ok, the american population.\n",
            "对 美 国 人 来 说\n",
            "==========\n",
            "or the swamp at gramercy park, right here.\n",
            "格 拉 姆 西 公 园 的 沼 泽 在 这 儿 ，\n",
            "==========\n",
            "i emailed \" chainsaw al \" dunlap, the asset stripper from the 1990s.\n",
            "我 电 邮 了 杀 手 艾 尔 dunlap 90 年 代 开 始 的 资 产 掠 夺 者\n",
            "==========\n",
            "so, as kevin kelly pointed out, there is no endgame.\n",
            "因 此 ， 诚 如 kevin kelly 所 说 ， 没 有 结 局 。\n",
            "==========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pajv5ridLamp"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1zqJXDsCUw-"
      },
      "source": [
        "We create a seq2seq model by using pretrained encoder + pretrained decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBVyNeKUv6FU",
        "outputId": "851e3a9b-81eb-49d1-e9c9-72690aa3c290"
      },
      "source": [
        "# loading pretrained model\n",
        "encoder_decoder = EncoderDecoderModel.from_encoder_decoder_pretrained(\n",
        "    encoder_pretrained_model_name_or_path=ENCODER_PRETRAINED,\n",
        "    decoder_pretrained_model_name_or_path=DECODER_PRETRAINED,\n",
        ")\n",
        "\n",
        "class Seq2SeqTrain(nn.Module):\n",
        "    def __init__(self, encoder_decoder):\n",
        "        super().__init__()\n",
        "        self.encoder_decoder = encoder_decoder\n",
        "        \n",
        "    def forward(self, batch):\n",
        "        input_ids, attention_mask, decoder_input_ids, decoder_attention_mask = batch\n",
        "\n",
        "        return self.encoder_decoder(\n",
        "                input_ids = input_ids,\n",
        "                attention_mask = attention_mask,\n",
        "                labels = decoder_input_ids,\n",
        "                decoder_input_ids=decoder_input_ids,\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at uer/gpt2-chinese-poem and are newly initialized: ['transformer.h.0.crossattention.q_attn.weight', 'transformer.h.8.crossattention.c_attn.weight', 'transformer.h.2.ln_cross_attn.weight', 'transformer.h.1.crossattention.bias', 'transformer.h.3.crossattention.c_proj.bias', 'transformer.h.11.ln_cross_attn.weight', 'transformer.h.1.crossattention.masked_bias', 'transformer.h.9.crossattention.bias', 'transformer.h.0.crossattention.masked_bias', 'transformer.h.1.crossattention.c_proj.bias', 'transformer.h.7.crossattention.q_attn.weight', 'transformer.h.7.ln_cross_attn.weight', 'transformer.h.10.crossattention.q_attn.weight', 'transformer.h.4.ln_cross_attn.weight', 'transformer.h.9.crossattention.q_attn.weight', 'transformer.h.2.crossattention.c_attn.weight', 'transformer.h.5.crossattention.masked_bias', 'transformer.h.3.ln_cross_attn.weight', 'transformer.h.10.crossattention.c_proj.weight', 'transformer.h.8.crossattention.masked_bias', 'transformer.h.5.crossattention.c_proj.weight', 'transformer.h.6.ln_cross_attn.weight', 'transformer.h.2.crossattention.c_proj.weight', 'transformer.h.9.crossattention.masked_bias', 'transformer.h.2.crossattention.masked_bias', 'transformer.h.1.crossattention.c_proj.weight', 'transformer.h.5.crossattention.c_proj.bias', 'transformer.h.3.crossattention.bias', 'transformer.h.4.crossattention.q_attn.weight', 'transformer.h.1.ln_cross_attn.weight', 'transformer.h.0.ln_cross_attn.weight', 'transformer.h.8.crossattention.q_attn.weight', 'transformer.h.8.crossattention.c_proj.weight', 'transformer.h.10.crossattention.c_attn.weight', 'transformer.h.11.crossattention.c_attn.weight', 'transformer.h.5.crossattention.bias', 'transformer.h.2.crossattention.c_proj.bias', 'transformer.h.6.crossattention.bias', 'transformer.h.3.crossattention.q_attn.weight', 'transformer.h.4.crossattention.c_proj.weight', 'transformer.h.4.crossattention.bias', 'transformer.h.7.crossattention.bias', 'transformer.h.3.crossattention.c_proj.weight', 'transformer.h.6.crossattention.c_attn.weight', 'transformer.h.0.crossattention.bias', 'transformer.h.6.crossattention.c_proj.bias', 'transformer.h.11.crossattention.c_proj.weight', 'transformer.h.1.crossattention.q_attn.weight', 'transformer.h.11.crossattention.c_proj.bias', 'transformer.h.9.crossattention.c_proj.weight', 'transformer.h.7.crossattention.c_proj.bias', 'transformer.h.0.crossattention.c_attn.weight', 'transformer.h.7.crossattention.c_proj.weight', 'transformer.h.2.crossattention.bias', 'transformer.h.8.ln_cross_attn.weight', 'transformer.h.1.crossattention.c_attn.weight', 'transformer.h.10.crossattention.c_proj.bias', 'transformer.h.3.crossattention.masked_bias', 'transformer.h.5.crossattention.c_attn.weight', 'transformer.h.4.crossattention.c_attn.weight', 'transformer.h.4.crossattention.c_proj.bias', 'transformer.h.10.crossattention.bias', 'transformer.h.11.crossattention.masked_bias', 'transformer.h.10.ln_cross_attn.weight', 'transformer.h.5.crossattention.q_attn.weight', 'transformer.h.4.crossattention.masked_bias', 'transformer.h.2.crossattention.q_attn.weight', 'transformer.h.9.crossattention.c_proj.bias', 'transformer.h.11.crossattention.bias', 'transformer.h.11.crossattention.q_attn.weight', 'transformer.h.6.crossattention.q_attn.weight', 'transformer.h.3.crossattention.c_attn.weight', 'transformer.h.6.crossattention.c_proj.weight', 'transformer.h.9.ln_cross_attn.weight', 'transformer.h.0.crossattention.c_proj.bias', 'transformer.h.7.crossattention.masked_bias', 'transformer.h.7.crossattention.c_attn.weight', 'transformer.h.0.crossattention.c_proj.weight', 'transformer.h.6.crossattention.masked_bias', 'transformer.h.5.ln_cross_attn.weight', 'transformer.h.9.crossattention.c_attn.weight', 'transformer.h.10.crossattention.masked_bias', 'transformer.h.8.crossattention.bias', 'transformer.h.8.crossattention.c_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uIjcPuXw0Fr"
      },
      "source": [
        "model = Seq2SeqTrain(encoder_decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBf3NTKSLcUb"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhFB_o7GK6-Y"
      },
      "source": [
        "learn = Learner(dls, model, loss_func=lambda output, target:output.loss,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "4wcfC9k9xCV8",
        "outputId": "cbef631e-ac51-4381-fcae-785476fc4fad"
      },
      "source": [
        "learn.fit(10, lr=5e-5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.961011</td>\n",
              "      <td>0.935475</td>\n",
              "      <td>38:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.847539</td>\n",
              "      <td>0.836173</td>\n",
              "      <td>38:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.815385</td>\n",
              "      <td>0.786844</td>\n",
              "      <td>38:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.766871</td>\n",
              "      <td>0.755473</td>\n",
              "      <td>38:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.727195</td>\n",
              "      <td>0.732940</td>\n",
              "      <td>38:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.701056</td>\n",
              "      <td>0.716719</td>\n",
              "      <td>38:19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.669514</td>\n",
              "      <td>0.704280</td>\n",
              "      <td>38:19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.651389</td>\n",
              "      <td>0.694713</td>\n",
              "      <td>38:19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.625053</td>\n",
              "      <td>0.690900</td>\n",
              "      <td>38:19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.609521</td>\n",
              "      <td>0.687882</td>\n",
              "      <td>38:18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL7Qco3ufM6_"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SFWnZ38_To0"
      },
      "source": [
        "model = model.cpu()\n",
        "model = model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtDEwRkK9ywz"
      },
      "source": [
        "def inference(text, starter=''):\n",
        "    tk_kwargs = dict(truncation=True, max_length=128, padding=\"max_length\",\n",
        "                     return_tensors='pt')\n",
        "    inputs = encoder_tokenizer([text,],**tk_kwargs)\n",
        "    with torch.no_grad():\n",
        "        return decoder_tokenizer.batch_decode(\n",
        "            model.encoder_decoder.generate(\n",
        "            inputs.input_ids,\n",
        "            attention_mask=inputs.attention_mask,\n",
        "            num_beams=3,\n",
        "            bos_token_id=101,\n",
        "        ),\n",
        "                                              skip_special_tokens=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1PqjVAX9ePa",
        "outputId": "14aa059c-e465-42c7-ea1d-e002be82b708"
      },
      "source": [
        "inference(\n",
        "    'And now my mission to control and predict had turned up the answer that the way to live is with vulnerability and to stop controlling and predicting.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[CLS] 我 的 目 的 就 是 预 测 来 控 制 这 个 预 测 ， 并 且 预']"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iTyaXZqfM7A",
        "outputId": "1341b9b6-93fe-484d-80c0-87b6cd5fe9ae"
      },
      "source": [
        "inference(\"I'm going to enjoy this movie\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[CLS] 我 很 喜 欢 这 部 电 影 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB0lpYlFfM7A",
        "outputId": "1532853f-4467-440a-e7e7-6c393ed1276c"
      },
      "source": [
        "inference(\"Why does this matter\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[CLS] 为 什 么 这 很 重 要 ？ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyneXGHbfM7A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}